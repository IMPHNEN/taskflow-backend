"""
Utility functions for AI services.
"""
import os
import json
import re
import logging
import datetime
from typing import Dict, Any, List
from uuid import uuid4

# Import the RESULTS_DIR from services config
from ..services.config import RESULTS_DIR

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def extract_json(content: str) -> Dict[str, Any]:
    """
    Extract JSON from content that may contain markdown or extra text.
    
    Args:
        content: The string content that may contain JSON
        
    Returns:
        Extracted and parsed JSON data
        
    Raises:
        ValueError: If JSON cannot be extracted or parsed
    """
    logger.info("🔍 Attempting to extract JSON from response...")
    json_match = re.search(r"```json\s*({.*?})\s*```", content, re.DOTALL)

    if json_match:
        logger.info("✅ Found JSON inside ```json block.")
        json_str = json_match.group(1).strip()
    else:
        # Try to find JSON without markdown formatting
        json_pattern = r"\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}"
        json_match = re.search(json_pattern, content)
        if json_match:
            logger.info("⚠️ Found JSON without markdown formatting.")
            json_str = json_match.group(0).strip()
        else:
            logger.warning("⚠️ No JSON block found, using raw content as-is.")
            json_str = content.strip()

    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"❌ Failed to parse extracted JSON: {e}\nRaw string:\n{json_str}")
        raise ValueError(f"Invalid JSON after extraction: {e}\nRaw JSON string:\n{json_str}")
    


def llm_to_tasks(generated_tasks: List[Dict[str, Any]], project_id: str) -> List[Dict[str, Any]]:
    """
    Convert LLM generated tasks into task records with proper UUIDs.
    
    Args:
        generated_tasks: List of task dictionaries generated by LLM
        project_id: ID of the project these tasks belong to
        
    Returns:
        List of task records with mapped UUIDs and project ID
    """
    logger.info(f"Converting {len(generated_tasks)} LLM generated tasks to task records")
    
    # First create a mapping of old IDs to new UUIDs
    id_mapping = {task['id']: str(uuid4()) for task in generated_tasks}
    
    task_records = []
    for task in generated_tasks:
        task_data = {
            'id': id_mapping[task['id']],
            'project_id': project_id,
            'title': task['title'],
            'description': task['description'],
            'task_type': task['task_type'],
            'position': task['position'],
            'story_point': 0,  # Set story point to 0
            'parent_id': id_mapping.get(task['parent_id']) if task['parent_id'] else None,
        }
        task_records.append(task_data)
    
    logger.info(f"✅ Successfully converted tasks with {len(task_records)} records")
    return task_records


def save_to_file(data: Dict[str, Any], filename: str) -> str:
    """
    Save data to a JSON file with timestamp.
    
    Args:
        data: Data to save
        filename: Base filename without extension
        
    Returns:
        Path to the saved file
    """
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = os.path.splitext(filename)[0]
    full_path = os.path.join(RESULTS_DIR, f"{base_name}_{timestamp}.json")
    
    with open(full_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)
    
    logger.info(f"✅ Data saved to: {full_path}")
    return full_path


def save_markdown(markdown_content: str, base_filename: str) -> str:
    """
    Save markdown content to a file with a timestamp.
    
    Args:
        markdown_content: The markdown content to save
        base_filename: The base name of the file without extension
        
    Returns:
        Path to the saved file
    """
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    full_path = os.path.join(RESULTS_DIR, f"{base_filename}_{timestamp}.md")
    
    with open(full_path, "w", encoding="utf-8") as f:
        f.write(markdown_content)
    
    logger.info(f"✅ Markdown saved to: {full_path}")
    return full_path 